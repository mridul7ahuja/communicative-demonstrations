{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from ddt import ddt, data, unpack\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Environments/')\n",
    "from ColoredGridWorld import OBMDP as targetCode\n",
    "from ColoredGridWorld.MDP import MDP\n",
    "from ColoredGridWorld import SetUpInferenceSpace as sup\n",
    "sys.path.append('../Algorithms/')\n",
    "import ActionInterpretation as AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......................\n",
      "----------------------------------------------------------------------\n",
      "Ran 23 tests in 0.080s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "@ddt\n",
    "class TestOBMDPConstruction(unittest.TestCase):\n",
    "    def setUp(self): \n",
    "        dimensions = (3,3)\n",
    "        goals = [(2,1)]\n",
    "        actions = [(-1,0),(0,1),(0,-1),(1,0)]\n",
    "        oneColourStates = {(0,0): 'white', (0,1): 'white', (0,2):'white', (1,0): 'white', (1,1): 'orange', (1,2):'white', (2,0): 'white', (2,1): 'yellow', (2,2):'white'}\n",
    "        convergenceTolerance = 10e-7\n",
    "        gamma = 0.94\n",
    "        alpha = 20\n",
    "        eps = 0.01\n",
    "        hyperparameters = (convergenceTolerance, gamma, alpha, eps)\n",
    "        oneColourUtilitySpace = [ {'white': 0, 'yellow': 10, 'orange': 0}, {'white': 0, 'yellow': 10, 'orange': -2} ]\n",
    "        transitionSpace = [True]\n",
    "        oneColourWorlds = sup.buildWorldSpace(oneColourUtilitySpace, transitionSpace)\n",
    "        oneColourEnvSpace = [(world, goal) for world, goal in product(oneColourWorlds, goals)]\n",
    "        oneColourEnvPolicySpace = sup.buildEnvPolicySpace(dimensions, oneColourStates, actions, oneColourEnvSpace, hyperparameters)\n",
    "        actionInterpretation = AI.ActionInterpretation(oneColourEnvPolicySpace)\n",
    "        self.literalObserver = targetCode.LiteralObserver(actionInterpretation)\n",
    "        bins = [0,0.25,0.5,0.75,1]\n",
    "        beliefSpacePossible = [{key:value for key, value in zip(oneColourEnvSpace, permutations)} for permutations in product(bins, repeat = len(oneColourEnvSpace))]\n",
    "        self.discreteBeliefSpace = [beliefVector for beliefVector in beliefSpacePossible if (sum(value for value in beliefVector.values())==1)]\n",
    "        hashableDiscreteBeliefSpace = [sup.HashableBelief(beliefVector) for beliefVector in self.discreteBeliefSpace]\n",
    "        getMDP = MDP(dimensions, oneColourStates, {'white': 0, 'yellow': 10, 'orange': 0} )\n",
    "        objectRewardFn, objectTransitionFn = getMDP()\n",
    "        self.getNextBelief = self.literalObserver(self.discreteBeliefSpace, True)\n",
    "        beliefUtilityFn = targetCode.getBeliefUtility()\n",
    "        jointStateSpace = list(product(oneColourStates.keys(), hashableDiscreteBeliefSpace))\n",
    "        getOBMDP = targetCode.OBMDP(jointStateSpace, (sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': 0}, True), (2,1)), True, 10)\n",
    "        self.jointRewardFn, self.jointTransitionFn = getOBMDP(objectTransitionFn, objectRewardFn, self.getNextBelief, beliefUtilityFn)\n",
    "\n",
    "    #case1: checking increase in utility, case2: checking boolean isInformative works, case3: checking no increase in utility, case4: checking negative utility\n",
    "    @data( ({'env1':0.5, 'env2':0.5}, {'env1':0.75, 'env2':0.25}, 'env1', True, 0.25),\n",
    "           ({'env1':0.5, 'env2':0.5}, {'env1':0.75, 'env2':0.25}, 'env1', False, 0),\n",
    "           ({'env1':0.4, 'env2':0.5, 'env3':0.1}, {'env1':0.7, 'env2':0.2, 'env3': 0.1}, 'env3', True, 0), \n",
    "           ({'env1':0.4, 'env2':0.5, 'env3':0.1}, {'env1':0.7, 'env2':0.2, 'env3': 0.1}, 'env2', True, -0.3) )\n",
    "    @unpack\n",
    "    def test_beliefUtility(self, beliefDict1, beliefDict2, trueEnv, isInformative, beliefUtilityExpected):\n",
    "        beliefUtilityFn = targetCode.getBeliefUtility()\n",
    "        beliefUtilityReceived = beliefUtilityFn(beliefDict1, beliefDict2, trueEnv, isInformative)\n",
    "        self.assertEqual(beliefUtilityReceived, beliefUtilityExpected)\n",
    "    \n",
    "    #last testcase checks for targetVector being exactly in the middle of possible beliefs (outputs nearest neighbour as the first vector encountered in list)\n",
    "    @data( (sup.HashableBelief({'x':0.6}), [{'x':0}, {'x':1}], {'x':1}),\n",
    "           (sup.HashableBelief({'x':0.6}), [{'x':0}, {'x':0.1}, {'x':0.2}, {'x':0.3}, {'x':0.4}, {'x':0.5}, {'x':0.6}, {'x':1}], {'x':0.6}),\n",
    "           (sup.HashableBelief({'x':100.8}), [{'x':105}, {'x':98}], {'x':98}),\n",
    "           (sup.HashableBelief({'x':0.5}), [{'x':0}, {'x':1}], {'x':0}) )\n",
    "    @unpack\n",
    "    def test_classLiteralObserver_getNearestNeighbour_1D(self, targetVectorDict, listOfVectorDicts, expectedNearestNeighbour):\n",
    "        nearestNeighbour = self.literalObserver.getNearestNeighbour(targetVectorDict, listOfVectorDicts)\n",
    "        self.assertEqual(nearestNeighbour(), expectedNearestNeighbour)\n",
    "        \n",
    "        \n",
    "    #last testcase checks for targetVector being exactly in the middle of possible beliefs (outputs nearest neighbour as the first vector encountered in list)\n",
    "    @data( (sup.HashableBelief({'x':0.75, 'y':0.7}), [{'x':0, 'y':0}, {'x':1, 'y':0}, {'x':1, 'y':1}, {'x':0, 'y':1}], {'x':1, 'y':1}),\n",
    "           (sup.HashableBelief({'x':18, 'y':27}), [{'x':0, 'y':0}, {'x':25, 'y':50}, {'x':25, 'y':0}, {'x':0, 'y':50}], {'x':25, 'y':50}),\n",
    "           (sup.HashableBelief({'x':0.5, 'y':0.5}), [{'x':0, 'y':0}, {'x':1, 'y':0}, {'x':1, 'y':1}, {'x':0, 'y':1}], {'x':0, 'y':0}) )\n",
    "    @unpack\n",
    "    def test_classLiteralObserver_getNearestNeighbour_2D(self, targetVectorDict, listOfVectorDicts, expectedNearestNeighbour):\n",
    "        nearestNeighbour = self.literalObserver.getNearestNeighbour(targetVectorDict, listOfVectorDicts)\n",
    "        self.assertEqual(nearestNeighbour(), expectedNearestNeighbour)\n",
    "       \n",
    "    #case1 and 2- choosing a path around the potential trap state which corresponds to it giving negative reward, case3: choosing a path through the potential trap state which corresponds to it being safe\n",
    "    @data( ( ((0,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (0,1), (0,2), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):1 }) ), \n",
    "           ( ((0,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (0,-1), (0,0), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):1 }) ), \n",
    "           ( ((0,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (1,0), (1,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):1, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0 }) ))\n",
    "    @unpack\n",
    "    def test_classLiteralObserver(self, jointState, action, nextObjectState, expectedBelief):\n",
    "        outputBelief = self.getNextBelief(jointState, action, nextObjectState)\n",
    "        self.assertEqual(outputBelief, expectedBelief)\n",
    "    \n",
    "    #both cases for moving to a non-informative state with 0 object reward. \n",
    "    @data( ( ((0,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (0,1), ((0,2), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):1 })) ), \n",
    "           ( ((0,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (0,-1), ((0,0), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):1 })) ) ) \n",
    "    @unpack\n",
    "    def test_OBMDP_jointRewardFunction_expectedRewardNegative(self, jointState, action, nextJointState):\n",
    "        outputReward = self.jointRewardFn(jointState, action, nextJointState)\n",
    "        self.assertTrue(outputReward<0)\n",
    "    \n",
    "    #case 1: moving to an informative state with 0 object reward, case 2 and 3: moving to goal state\n",
    "    @data( ( ((0,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (1,0), ((1,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):1, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0 })) ), \n",
    "           ( ((1,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (1,0), ((2,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })) ), \n",
    "           ( ((2,0), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })), (0,1), ((2,1), sup.HashableBelief({(sup.HashableWorld({'white':0, 'yellow':10, 'orange':0}, True), (2,1)):0.5, (sup.HashableWorld({'white':0, 'yellow':10, 'orange':-2}, True), (2,1)):0.5 })) ) )\n",
    "    @unpack\n",
    "    def test_OBMDP_jointRewardFunction_expectedRewardPositive(self, jointState, action, nextJointState):\n",
    "        outputReward = self.jointRewardFn(jointState, action, nextJointState)\n",
    "        self.assertTrue(outputReward>0)\n",
    "\n",
    "    @data( ( ((0,1), sup.HashableBelief({(sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': 0}, True),(2,1)):0.5, (sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': -2}, True), (2,1)):0.5})), (0,1) ), \n",
    "           ( ((1,2), sup.HashableBelief({(sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': 0}, True),(2,1)):0.5, (sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': -2}, True), (2,1)):0.5})), (1,0) ) )\n",
    "    @unpack\n",
    "    def test_jointTransitionFunction_checkDeterminsitic(self, jointState, action):\n",
    "        nextStateDictionary = self.jointTransitionFn(jointState, action)\n",
    "        numberOfNextStates = len(list(nextStateDictionary.keys()))\n",
    "        self.assertEqual(numberOfNextStates, 1)\n",
    "        \n",
    "        \n",
    "    @data( ((((0,1), sup.HashableBelief({(sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': 0}, True),(2,1)):0.5, (sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': -2}, True), (2,1)):0.5})), (0,1), ((0,2), sup.HashableBelief({(sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': 0}, True), (2,1)):0, (sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': -2}, True), (2,1)):1})))), \n",
    "           ((((0,1), sup.HashableBelief({(sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': 0}, True),(2,1)):0.5, (sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': -2}, True), (2,1)):0.5})), (1,0), ((1,1), sup.HashableBelief({(sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': 0}, True), (2,1)):1, (sup.HashableWorld({'white': 0, 'yellow': 10, 'orange': -2}, True), (2,1)):0})))) )\n",
    "    @unpack\n",
    "    def test_jointTransitionFunction_checkNextJointState(self, jointState, action, nextJointState):\n",
    "        probabilityOfTransition = self.jointTransitionFn(jointState, action)[nextJointState]\n",
    "        expectedProbability = 1\n",
    "        self.assertEqual(probabilityOfTransition, expectedProbability)\n",
    "    \n",
    "    def tearDown(self):\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
